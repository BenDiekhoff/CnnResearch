{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import numpy\n",
    "# numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# baseline cnn model for mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import load_model\n",
    " \n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "    #print (f\"TRIAN Y\\n {trainY}, \\n\\n\\nTEST Y\\n{testY}\")\n",
    "    \n",
    "    # print(len(trainX))\n",
    "    # print(len(trainY))\n",
    "\n",
    "    # print(len(testX))\n",
    "    # print(len(testY))\n",
    "\n",
    "    # reshape dataset to have a single color channel\n",
    "    # trainX.shape is 60000,28,28\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    # trainX.shape is 60000,28,28,1\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    \n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "\n",
    "    # for x in trainY[1]:\n",
    "    #     print (x)\n",
    "    testY = to_categorical(testY)\n",
    "    # print (f\"TRAIN X{trainX},\\n\\n\\nTRIAN Y {trainY}, \\n\\n\\nTEST X{testX}, \\n\\n\\nTEST Y{testY}\")\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    #32 filters, each 3x3\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    \n",
    "    #batch normalization (turns out to not do much) -from the improvement to learning section\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    #2x2 max pooling layer\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    #more filters -from the increase in model depth section\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    #flatten the pools\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "   \n",
    "    #batch normalization (turns out to not do much) -from the improvement to learning section\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #print(type(model))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "    scores, histories = list(), list()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    # enumerate splits\n",
    "    # print(len(dataX))\n",
    "    # print(dataX[0][0][0])\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "        # define model\n",
    "        model = define_model()\n",
    "\t\t# select rows for train and test\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        # fit model\n",
    "        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        # stores scores\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(2, 1, 1)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(2, 1, 2)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\ttrainX, testX = prep_pixels(trainX,testX)\n",
    "\tscores, histories = evaluate_model(trainX,trainY)\n",
    "\tprint (scores, histories)\n",
    "\tsummarize_diagnostics(histories)\n",
    "\tsummarize_performance(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the Save Final Model sections\n",
    "def run_test_harness_save():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
    "\t# save model\n",
    "\tmodel.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the Evaluate Final Model section\n",
    "def run_test_harness_eval():\n",
    "    # load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# evaluate model on test dataset\n",
    "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_test_harness()\n",
    "# run_test_harness_save()\n",
    "# run_test_harness_eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('handwriting': conda)",
   "language": "python",
   "name": "python37664bithandwritingconda4e9b69477be2448e84e1fa8f16d19b1c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}